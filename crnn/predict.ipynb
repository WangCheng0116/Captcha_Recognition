{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from model import CNNLSTM  # Ensure CNNLSTM model architecture is defined\n",
    "from sklearn import preprocessing\n",
    "import config \n",
    "import albumentations\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2672884895.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    lbl_enc.classes_ = np.load(\"C:\\Users\\kevin\\Desktop\\src(1)\\label_classes.npy\", allow_pickle=True)  # Assuming you saved label classes during training\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Load the label encoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "lbl_enc.classes_ = np.load(\"label_classes.npy\", allow_pickle=True)  # Assuming you saved label classes during training\n",
    "\n",
    "# Load the model and its weights\n",
    "model = CNNLSTM(image_width=config.IMAGE_WIDTH, image_height=config.IMAGE_HEIGHT, num_classes=len(lbl_enc.classes_))\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "model.to(config.DEVICE)\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    This is for model without noise preprocessing\n",
    "    \"\"\"\n",
    "    # augmentations = albumentations.Compose(\n",
    "    #     [albumentations.Normalize(always_apply=True)])\n",
    "    # # image = Image.open(image_path)\n",
    "    # image = image.convert(\"L\")\n",
    "\n",
    "    # image = image.resize(\n",
    "    #         (config.IMAGE_WIDTH, config.IMAGE_HEIGHT), resample=Image.BILINEAR\n",
    "    #     )\n",
    "\n",
    "    # image = np.array(image).astype(np.float32)\n",
    "    # image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # augmented = augmentations(image=image)\n",
    "    # image = augmented[\"image\"]\n",
    "\n",
    "    # return torch.tensor(image, dtype=torch.float)\n",
    "\n",
    "    \"\"\"\n",
    "    This is for model with noise preprocessing\n",
    "    \"\"\"\n",
    "    augmentations = albumentations.Compose(\n",
    "            [albumentations.Normalize(always_apply=True)])\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    image = np.array(image).astype(np.float32)\n",
    "\n",
    "    image[image == 0] = 255\n",
    "    image[image < 255] = 0\n",
    "\n",
    "    # Convert back to PIL Image for resizing\n",
    "    image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = image.resize(\n",
    "        (config.IMAGE_WIDTH, config.IMAGE_HEIGHT), resample=Image.BILINEAR\n",
    "    )\n",
    "    image = np.array(image).astype(np.float32)\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    augmented = augmentations(image=image)\n",
    "    image = augmented[\"image\"]\n",
    "\n",
    "    return torch.tensor(image, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Function to decode predictions\n",
    "def decode_predictions(preds, encoder):\n",
    "    preds = preds.permute(1, 0, 2)  # Reshape predictions as needed\n",
    "    preds = torch.softmax(preds, 2)\n",
    "    preds = torch.argmax(preds, axis=2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    cap_preds = []\n",
    "    for j in range(preds.shape[0]):\n",
    "        temp = []\n",
    "        for k in preds[j, :]:\n",
    "            k = k - 1\n",
    "            if k == -1:\n",
    "                temp.append(\"-\")\n",
    "            else:\n",
    "                temp.append(encoder.inverse_transform([k])[0])\n",
    "        tp = \"\".join(temp)\n",
    "        cap_preds.append(tp)\n",
    "    return cap_preds\n",
    "\n",
    "def postprocess(pred_text):\n",
    "    # Remove placeholder characters\n",
    "    pred_text = pred_text.replace(\"-\", \"\")  # Adjust to remove any specific placeholder character\n",
    "    # Remove consecutive duplicate characters\n",
    "    result = []\n",
    "    for i, char in enumerate(pred_text):\n",
    "        if i == 0 or char != pred_text[i - 1]:  # Only append if it's not a consecutive duplicate\n",
    "            result.append(char)\n",
    "    return ''.join(result)\n",
    "\n",
    "# Prediction function\n",
    "def predict(image):\n",
    "    # Preprocess the image\n",
    "    image_tensor = preprocess_image(image)\n",
    "    image_tensor = image_tensor.to(config.DEVICE)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        output = model(image_tensor.unsqueeze(0))  # Add batch dimension\n",
    "        predictions = decode_predictions(output, lbl_enc)\n",
    "        \n",
    "    return predictions[0]  # Return decoded prediction for the image\n",
    "\n",
    "\n",
    "def evaluate(test_dir):\n",
    "    test_path = Path(test_dir)\n",
    "    correct_captchas = 0\n",
    "    correct_chars = 0\n",
    "    total_captchas = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    for img_path in test_path.glob(\"*.png\"):\n",
    "        total_captchas += 1\n",
    "        true_label = img_path.stem.split('-')[0].lower()\n",
    "        total_chars += len(true_label)\n",
    "\n",
    "        # Load and predict\n",
    "        image = Image.open(str(img_path))\n",
    "        predicted = postprocess(predict(image))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        if predicted == true_label:\n",
    "            correct_captchas += 1\n",
    "\n",
    "        # Character-level accuracy\n",
    "        for pred_char, true_char in zip(predicted, true_label):\n",
    "            if pred_char == true_char:\n",
    "                correct_chars += 1\n",
    "\n",
    "    captcha_accuracy = correct_captchas / total_captchas\n",
    "    char_accuracy = correct_chars / total_chars\n",
    "\n",
    "    return {\n",
    "        'captcha_accuracy': captcha_accuracy,\n",
    "        'character_accuracy': char_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(\"C:\\\\Users\\\\kevin\\\\Desktop\\\\src(1)\\\\data\\\\test\")\n",
    "print(f\"CAPTCHA Accuracy: {results['captcha_accuracy']:.2%}\")\n",
    "print(f\"Character Accuracy: {results['character_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved losses\n",
    "losses = np.load('losses.npy', allow_pickle=True).item()\n",
    "\n",
    "train_losses = losses['train_losses']\n",
    "valid_losses = losses['valid_losses']\n",
    "\n",
    "# Plotting the train and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(valid_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
